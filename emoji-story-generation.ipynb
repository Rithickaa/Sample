{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPX1k/j+dIdaCnyt4etcpGi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rithickaa/Sample/blob/main/emoji-story-generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgX3pJzHKpiK",
        "outputId": "966ae37e-32c0-4510-f9f7-5455b4f73e83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ú® Emoji Input: üê±üöÄüåå\n",
            "\n",
            "üìñ Generated Story:\n",
            "\n",
            "my world was filled with two different stories. I was a teen living in a small city, and I read a lot of books, but I was always fascinated by books. I didn't know much about math or science until I started reading comics. As a kid, I always wanted to be a math teacher, but I had no idea how to teach this kind of subject. After reading a few books, I discovered that books and comics could both be useful in learning and to socialize with. I started working on the story concept of Misha, and I wanted to start my own comic book series. It was a good idea, and I started looking into it. I love comics, and I hope that by doing so, I might inspire other children who are interested in learning to make better and smarter comics.\n",
            "\n",
            "I love the books. They show how important it is to create the story, and give us the ability to create awesome stories that we all love. You know what, I'll never know when they're gonna see it again. I love comics.\n",
            "\n",
            "So I wanted to create a story with the same emotional impact as the first story. I wanted to tell a story that is as realistic as possible. I wanted to feel like a child who\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers --quiet\n",
        "from transformers import pipeline, set_seed\n",
        "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
        "set_seed(42)\n",
        "def emoji_to_story(emojis, max_length=100):\n",
        "    prompt = f\"Create a fun and imaginative short story based on these emojis: {emojis}\\n\\nOnce upon a time,\"\n",
        "    result = generator(\n",
        "        prompt,\n",
        "        max_length=max_length,\n",
        "        temperature=0.9,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "        do_sample=True,\n",
        "        num_return_sequences=1,\n",
        "        eos_token_id=50256\n",
        "    )\n",
        "    story = result[0]['generated_text']\n",
        "    return story.replace(prompt, \"\").strip()\n",
        "emojis = \"üê±üöÄüåå\"\n",
        "story = emoji_to_story(emojis)\n",
        "print(\"‚ú® Emoji Input:\", emojis)\n",
        "print(\"\\nüìñ Generated Story:\\n\")\n",
        "print(story)\n"
      ]
    }
  ]
}